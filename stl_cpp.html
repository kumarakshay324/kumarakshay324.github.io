    <!DOCTYPE HTML>

<head>
<style>

div.blog_box {
  margin-left: 30%;
  margin-right: 10%;

  background-color: #f5f5ef;
  /*border: 1px black;*/
  opacity: 1.0;
  filter: alpha(opacity=100); /* For IE8 and earlier */
}

div.column{
  /*float: right;*/
  margin-right: 0%;
  width: 30%;
  position: fixed;
}

code { 
  font-family: monospace;
}

</style>
</head>

<html>
    <head>
        <title>AKSHAY  KUMAR</title>
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <meta name="description" content="" />
        <meta name="keywords" content="" />
        <!--[if lte IE 8]><script src="css/ie/html5shiv.js"></script><![endif]-->
        <script src="js/jquery.min.js"></script>
        <script src="js/jquery.dropotron.min.js"></script>
        <script src="js/skel.min.js"></script>
        <script src="js/skel-layers.min.js"></script>
        <script src="js/init.js"></script>
        <noscript>
            <link rel="stylesheet" href="css/skel.css" />
            <link rel="stylesheet" href="css/style.css" />
        </noscript>
        <!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
    </head>
    <body class="homepage">

        <!-- Header Wrapper -->
            <div class="wrapper style1">
            
            <!-- Header -->

                <div id="header">
                    <div class="container">
                            
                        <!-- Logo -->
                            <h1><a href="#" id="logo">Solarize</a></h1>
                        
                        <!-- Nav -->
                            <nav id="nav">
                                <ul>
                                    <li class="active"><a href="portfolio.html">PORTFOLIO</a></li>                                  
                                    <li class="active"><a href="images/AKSHAY_KUMAR_RESUME_1PAGE.pdf">RESUME</a></li>

                                    <li class="active"><a href="index.html">WELCOME</a></li>
                                    <li>
                                        <a href="">NAVIGATE</a>
                                        <ul>
                                            <li><a href="portfolio.html">PORTFOLIO</a></li>
                                            <li><a href="http://www.zine.co.in" target="_blank">ZINE RESEARCH GROUP</a></li>
                                            <li><a href="posts.html">POSTS</a></li>
                                            <li><a href="contact.html">CONTACT</a></li>
                                        </ul>
                                    </li>
                                </ul>
                            </nav>
    
                    </div>
                </div>
                
            <!-- Banner -->
    <!--                <div id="banner">
                        <section class="container">
                            <span style="font-size:80px;color:black"><b>AKSHAY KUMAR</b></span>
                            <span style="font-size:25px;color:black" >  <b>MASTERS IN ROBOTICS ENGINEERING</b> | WORCESTER POLYTECHNIC INSTITUTE </span>
                            <span style="font-size:40px;color:black"> PORTFOLIO </span>

                            </section>
                    </div>
 -->
            </div>          

            <!-- Introduction -->
            <div class="wrapper style5" align="justify" >

            <br>

            <div class="column">
                <div class="blog_box" align="justify" >
                    <center>
                    <br>
                    <p style="font-size:20px;">LATEST POSTS</p>
                    </center>

                    <a style="display:block;font-size:13px;color:black;;text-decoration:none;margin-left:2%;margin-right:10%margin-top:5%" 
                    href="slam_intro.html">
                        <p style="margin-right:5%">&#128462 Simulataneous Localization and Mapping - An Introduction</p>
                    </a>

                    <a style="display:block;font-size:13px;color:black;;text-decoration:none;margin-left:2%;margin-right:10%margin-top:5%" 
                    href="mp_intro.html">
                        <p style="margin-right:5%">&#128462 Motion Planning in Robotics - Yet Another Introduction!</p>
                        <br>
                    </a>
                    <br>
                </div>
                
            </div>

            <div class="blog_box" align="justify" >
                    <!-- <center><img src="images/posts.jpg" style="width:1120px;height:706px;margin-left:5%;"></center> -->
                <br>
                    <h2 style="font-size:40px">STL Algorithms in C++</h2>
                <br>


                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;">

                    The Standard Template Library in C++ is a large native library in C++ that provides in-built data structures and algorithms. It is a collection of containers, iterations and algorithms. STL is templated and thus supports multiple variants of data types like vectors, lists, deque, arrays, heaps and sets. 

                    This article talks about the general algorithms for searching, sorting and queries applicable to these containers.
                </p>

                <center>
                    <figure>
                        <img src="images/stl_overview.png" style="width:622px;height:390px;">
                        <figcaption>STL Overview</figcaption>
                    </figure>


                    <br><br>
                </center>
                <h1 style="text-align:left;margin-left:200px;font-size:20px; ">Introduction</h1>
                <br>

                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;">

                This list of algorithms is not exhaustive yet contains the most common and# useful C++ native algorithms in the STL library. Any of these algorithms can be written again though the efficiency of the same would atmost be comparable to the same available in the STL libraries.

                <br><br>
                <h1 style="text-align:left;margin-left:200px;font-size:20px ">Algorithms for Heaps</h1>
                <br>
                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;">
                        
                    Create a heap from vector of numbers <br>
                    <code> 
                        std::make_heap(vector.begin(), vector.end())
                    </code><br><br>

                    Add contents to a heap (it handles the pushing of numbers and arranges them in the heap based on the comparison)
                    <br>
                    <code> 
                        std::push_heap(vector.begin(), vector.end())
                    </code><br><br>


                    Pop out the highest number
                    <br>
                    <code> 
                        std::pop_heap(vector.begin(), vector.end())
                    </code><br><br>

                </p> 

                <center>
                    <figure>
                        <img src="images/coverage/f2.png" style="width:622px;height:390px;">
                        <figcaption>Figure 2 - Mobile Robot Localization</figcaption>
                    </figure>

                    <br><br>
                </center>

                <li style="text-align:left;margin-left:200px "> Probabilistic Techniques  </li>
                <br>    
                <p style="column-width:1000px;margin-left:220px;margin-right:200px;text-align:justify;">
                Such techniques generally draw a probable distribution of robot positioning on the map
                and then further reduce it down to deterministic values using sensor and trial
                movements. All probabilistic techniques depend upon inputs from ​perception ​model ​(
                robot’s idiothetic sources tell it about its own motion, proprioception and robot’s
                allothetic sources tell it about the world - camera, lidar and laser sensors ) and ​action
                model ​(like odometry information and wheel revolution based distance covered - subject
                to errors accrued over time)</p>

                <p style="column-width:1000px;margin-left:250px;margin-right:200px;text-align:justify;"> <i> <b>Markov Localization</b></i> </p>

                <p style="column-width:1000px;margin-left:250px;margin-right:200px;text-align:justify;"> In this technique, the robot starts with an arbitrarily defined probability distribution
                of the robot’s position on the map over discrete positions and updates these beliefs over
                time., The prior probabilities are updated using sensor data like encoder values and
                laser scans and given it the conditions to discard or support probabilities over the
                locations. The process of keeping track of probabilities over the complete map, for all
                discretized possible locations, and re-computing probabilities over all of them makes the
                process computationally expensive but still helpful as it addresses all the possibilities.
                The perception model is used to individually update all probabilities over the possible
                locations using Bayes formula. It could work for both, topological as well as grid maps,
                but given the generality of the algorithm, it tends to be very inefficient.</p>

                <p style="column-width:1000px;margin-left:250px;margin-right:200px;text-align:justify;"> <i> <b>Kalman Localization</b></i> </p>

                <p style="column-width:1000px;margin-left:250px;margin-right:200px;text-align:justify;"> This method considers the robot’s possible location on the map as a single
                Gaussian probability distribution where the mean and covariance values are repeatedly
                updated to get to the best representation of its pose. Kalman Localization works on
                using the transition model, that is the robot’s <b></b> ​action model that updates its likelihood
                factors and the plant model that is the ​perception model ​that gives another estimate of
                the future pose in the map. It combines information from the two to get final localization
                values. The prediction step works on movement prior movement information to predict
                new locations and then the same is estimated via the sensors that see the environment;
                finally culminating the update by fusing the two information.<br><br>

                An example to this could be that the robot starts with a random Gaussian belief of its
                position, takes a small move, records this to predict new position with the existing
                Gaussian belief, then uses sensors to view the surroundings (distance from the edges
                of the maps and relative position to certain landmarks on the map) and estimate its
                location on the map and finally using the two hypotheses to find a better Gaussian
                probability representation. This iterative techniques terminates when further updates
                make the probabilities to converge and the resultant distribution shows where the robot
                could best be in the map. Very often, the high-class sensing systems help make this
                distribution deterministic with a very narrow region of uncertainty.</p>

                <li style="text-align:left;margin-left:200px "> Landmark based Localization  </li>
                <br>    
                <p style="column-width:1000px;margin-left:220px;margin-right:200px;text-align:justify;">
                Another category of localization could scenario where the environment is customized for
                robot navigation. These cases include easy to sense RFID tags on the floor or shelves
                of a warehouse, visual landmark coding that represents the corresponding position on
                the map or otherwise. Such practices are fairly simple but obviously not efficient to be
                duplicated under time and money constraints. Beacon systems, artificial floor markers
                and GPS based location estimation are also examples of the same. The robot
                processes such highly informative tags and compares it with a pre-fed look-up table for
                the same and finds the best match of the location, deterministically on most of the
                occasion.</p>

                <li style="text-align:left;margin-left:200px "> Computer Vision based Localization  </li>
                <br>    
                <p style="column-width:1000px;margin-left:220px;margin-right:200px;text-align:justify;">
                Use of visual feed could be incorporated in both of the above techniques but using
                machine vision explicitly to explore the environment while tracking own motion, building
                an own version of the map and then trying to fit this generated map to a subset of the
                global map can also be used.
                In our approach to solving the coverage problem, localization is the first step that
                determines robot’s motion. It is followed by methods to reach and decompose the
                arbitrary coverage area into units and reduce the complexity of the task.</p>

                <h1 style="text-align:left;margin-left:200px;font-size:20px ">Coverage Area Decomposition Techniques</h1>
                <br>
                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;">
                The coverage area for the task could be any arbitrary section, either continuous or
                sporadically distributed over the complete map. This makes robot understand the
                complexity of the task and reduce it to simpler individually addressable sections. 
                <br><br> The complex scenarios for coverage areas could be:</p> 


                <li style="text-align:left;margin-left:200px;margin-right:200px;text-align:justify;"> The area is not a perfect polygon with standard angles on the edges. User inputs
                using haptic devices and other manual inputs devices or using drawing tools
                could form very inconsistent edges and angles. A comparative version of
                standard computationally defined coverage area and a manual-input defined
                coverage area is shown in ​<b>Figure 3 </b>  </li>
                <br>    

                <center>
                    <figure>
                        <img src="images/coverage/f3.png" style="width:435px;height:273px;">
                        <figcaption>Figure 3 - Coverage Area With Irregular Boundaries</figcaption>
                    </figure>

                    <br><br>
                </center>

                <li style="text-align:left;margin-left:200px;margin-right:200px;text-align:justify;"> The coverage area includes voids in centers and demands robot motion in a way
                that the robot should eventually find a way out of the area, doesn’t get stuck in it.
                An example of such scenario can also be seen in <b>​Figure 4</b> </li>
                <br>    


                <center>
                    <figure>
                        <img src="images/coverage/f4.png" style="width:435px;height:273px;">
                        <figcaption>Figure 4 - Coverage Area With voids within</figcaption>
                    </figure>

                    <br><br>
                </center>

                <li style="text-align:left;margin-left:200px;margin-right:200px;text-align:justify;"> The coverage area is discontinuous and distributed all over the map and the
                robot needs to determine the optimal strategy where incorrect sequence of
                handling the zones could trap the robot. An example of this special problem is
                shown in <b>Figure 5</b> ​. Here the blue strips are to be painted and the robot starts at
                one edge of the map which is its docking zone. The robot could instantly start
                painting but would end up in trapped on the other end of the map. So, it should
                understand that even though travelling to other end of the and then starting to
                paint involves more work, it prevents chances of getting trapped with no rescue
                options.</li>
                <br>    

                <center>
                    <figure>
                        <img src="images/coverage/f5.png" style="width:435px;height:273px;">
                        <figcaption>Figure 5 - Coverage Area with Discontinuities</figcaption>
                    </figure>

                    <br><br>
                </center>

                <li style="text-align:left;margin-left:200px;margin-right:200px;text-align:justify;"> The coverage zones are smaller than the robot footprint and navigation to such
                zones has only one approach. Such a problem could be seen in ​ <b>Figure 6</b> ​.</li>
                <br>

                <center>
                    <figure>
                        <img src="images/coverage/f6.png" style="width:435px;height:273px;margin-left:50px;">
                        <figcaption>Figure 6 - Coverage Area With zones with area less than robot footprint</figcaption>
                    </figure>

                    <br><br>
                </center>



                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;">
                All such special problems of coverage firstly need the robot to have a clear
                understanding of the mapping information and then start the decomposition into viable,
                individually approachable zones.
                <br><br> The different mapping techniques include:</p>

                <li style="text-align:left;margin-left:200px;margin-right:200px;text-align:justify;"> Metric or Topological maps where the complete area is placed on a 2D
                coordinate frame and any point in the area is mapped with a particular position in
                the frame, either using cartesian or polar representation. While Cartesian
                presentation helps represent discrete points, polar representation helps in
                comparing robot’s current heading and distance with respect to origin with that of
                the target and thus aligns with navigation tasks’ necessities</li>
                <br>                 

                <li style="text-align:left;margin-left:200px;margin-right:200px;text-align:justify;"> Grid based maps are where the complete are is divided into several square grids
                of predefined size, generally equal to the robot footprint. Since areas need not be
                perfectly rectangular and thus can’t have finite grids; the smaller sections are
                represented as a part of the grid with smaller sections of varying granularity that
                cover all tiny zones.</li>
                <br>                 

                <li style="text-align:left;margin-left:200px;margin-right:200px;text-align:justify;">Certain maps could also be built to overlay on the standard maps. Such a
                representation would be having the distances between landmarks as certain
                nodes on the map while the obstacle free path between them represents a
                traversable path called an arc. </li>
                <br>                 

                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;">
                Based on the mapping used, the robot needs to identify the best decomposition of the
                coverage area such that each smaller version is individually addressable and it
                encompasses the complete coverage area without missing zones. Following techniques
                are proposed to reduce the coverage area into simpler accessible zones.</p>

                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;"> <b>Boustrophedon Decomposition</b></p>
                <li style="text-align:left;margin-left:200px;margin-right:200px;text-align:justify;"> Here, the complete map is subdivided into several parallel strips that can be covered
                using the zig-zag motion that covers area equal to the width of the robot footprint. This
                eases out robot’s motion in each individual strip as it simply supposed to cover each
                strip once and that zone of the coverage area is worked upon.
                However, this is easily applicable easily to polygonal areas with right-angled edges no
                awkwardly angled edges exist on the strip. ​Figure 7 shows a comparative illustration of
                where this decomposition would work or where it might not work.</li>
                <br>                 

                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;"> <b>Trapezoidal Decomposition</b></p>
                <li style="text-align:left;margin-left:200px;margin-right:200px;text-align:justify;"> Just like the above decomposition, here we could use trapezoidal shapes to divided the
                coverage area into simpler zones that can be traversed using the zig-zag motion.
                However, this tends to create several unnecessary smaller sections that could have
                been essentially merged and used in the above technique.</li>
                <br>                 

                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;"> <b>Rectangular sub-sections with grids of variable granularity for remaining zones of non-standard dimensions - A subclass of Boustrophedon Decomposition</b></p>
                <li style="text-align:left;margin-left:200px;margin-right:200px;text-align:justify;"> As the heading suggest, we try to break the coverage area into large unoccupied with
                obstacle zones that can be covered easily by the robot’s sweeping or cyclic motion(to
                be discussed later). It is tried that such sections’ edges align with the polygonal edges
                and the broken zones allow traversal with between adjacent ones. There should exist a
                path that connects adjacent sections</li>
                <br>                 

                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;"> <b>4. Random zones for random motion</b></p>
                <li style="text-align:left;margin-left:200px;margin-right:200px;text-align:justify;"> This is the easiest technique to be implemented in coverage problems where the map is
                divided into random zones or shapes larger than the robot footprint and the robot could
                make random sweeps within each of them. Theoretically, as time tends to infinity(very
                large time span of operation), all points would have been covered. This technique is the
                most extravagant one and just a theoretical approach to improve upon.</li>
                <br>                 

            </div>
            </div>
    
        <!-- Section One -->
            <div class="wrapper style2">

                <p style="margin-bottom:0;padding-bottom:0;"><hr width="50%"><center>Copyright @Akshay Kumar | Last Updated on 05/25/2019</center></p> 

            </div>
<div align=center><a href='https://www.counter12.com'><img src='https://www.counter12.com/img-y9Z8xYWb7W273YW2-50.gif' border='0' alt='counter'></a><script type='text/javascript' src='https://www.counter12.com/ad.js?id=y9Z8xYWb7W273YW2'></script></div>

    </body>
</html>
