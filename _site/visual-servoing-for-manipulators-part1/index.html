<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Visual Servoing For Manipulators - Part I | ThatRobotBoy</title>

    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Visual Servoing For Manipulators - Part I | ThatRobotBoy</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Visual Servoing For Manipulators - Part I" />
<meta name="author" content="akshay" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Visual Servoing is one of the most used robotics in the industry for automation. It involves using computer-vision based realtime feedback of the task space for online control of manipulator end-effector pose while performing tasks. Servoing refers to using a closed-loop feedback mechanism to manipulate reference input signal to a system while eventually driving the system to the desired target. Extracted features from visual information relate the robot current configuration to the task at hand and the system generates high-level pose control commands towards task completion." />
<meta property="og:description" content="Visual Servoing is one of the most used robotics in the industry for automation. It involves using computer-vision based realtime feedback of the task space for online control of manipulator end-effector pose while performing tasks. Servoing refers to using a closed-loop feedback mechanism to manipulate reference input signal to a system while eventually driving the system to the desired target. Extracted features from visual information relate the robot current configuration to the task at hand and the system generates high-level pose control commands towards task completion." />
<link rel="canonical" href="http://localhost:4000/visual-servoing-for-manipulators-part1/" />
<meta property="og:url" content="http://localhost:4000/visual-servoing-for-manipulators-part1/" />
<meta property="og:site_name" content="ThatRobotBoy" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-27T00:00:00-08:00" />
<script type="application/ld+json">
{"description":"Visual Servoing is one of the most used robotics in the industry for automation. It involves using computer-vision based realtime feedback of the task space for online control of manipulator end-effector pose while performing tasks. Servoing refers to using a closed-loop feedback mechanism to manipulate reference input signal to a system while eventually driving the system to the desired target. Extracted features from visual information relate the robot current configuration to the task at hand and the system generates high-level pose control commands towards task completion.","author":{"@type":"Person","name":"akshay"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/visual-servoing-for-manipulators-part1/"},"datePublished":"2019-01-27T00:00:00-08:00","@type":"BlogPosting","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"},"name":"akshay"},"headline":"Visual Servoing For Manipulators - Part I","dateModified":"2019-01-27T00:00:00-08:00","url":"http://localhost:4000/visual-servoing-for-manipulators-part1/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.ico">

    <!-- Font Awesome Icons -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">

    <!-- Google Fonts-->
    <link href="https://fonts.googleapis.com/css?family=Dosis:400,400i,700" rel="stylesheet">

    <!-- Google Fonts-->
    <link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">

    <!-- Bootstrap Modified -->
    <link rel="stylesheet" href="/assets/css/main.css">

    <!-- Theme Stylesheet -->
    <link rel="stylesheet" href="/assets/css/theme.css">

    <!-- Jquery on header to make sure everything works, the rest  of the scripts in footer for fast loading -->
    <script
    src="https://code.jquery.com/jquery-3.3.1.min.js"
    integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
    crossorigin="anonymous"></script>

    <!-- This goes before </head> closing tag, Google Analytics can be placed here --> 


</head>

<body class="">

    <!-- Navbar -->
    <nav id="MagicMenu" class="topnav navbar navbar-expand-lg navbar-light bg-white fixed-top">
    <div class="container">
        <a class="navbar-brand text-indigo" href="/index.html"><strong>ThatRobotBoy</strong></a>
        <button class="navbar-toggler collapsed" type="button" data-toggle="collapse" data-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
        </button>
        <div class="navbar-collapse collapse" id="navbarColor02" style="">
            <ul class="navbar-nav mr-auto d-flex align-items-center">
               <!--  Replace menu links here -->

<li class="nav-item">
<a class="nav-link" href="/index.html">Home</a>
</li>
<li class="nav-item">
<a class="nav-link" href="/author-akshay.html">About Me</a>
</li>
<li class="nav-item">
<a class="nav-link btn btn-white" href="/projects.html">Projects</a>
</li>
<li class="nav-item">
<a class="nav-link" href="/publications.html">Publications</a>
</li>
<li class="nav-item">
<a class="nav-link" href="/skills.html">Skills</a>
</li>
<li class="nav-item">
<a class="nav-link" href="/assets/documents/AKSHAY_KUMAR_RESUME_1PAGE.pdf">Resume</a>
</li>
<!-- <li class="nav-item">
<a class="nav-link" href="/contact.html">Contact</a>
</li> -->

            </ul>
        </div>
    </div>
    </nav>

    <!-- Search Results -->
    <div id="lunrsearchresults">
        <ul class="mb-0"></ul>
    </div>

    <!-- Content -->
    <main role="main" class="site-content">
        
<div class="container">
<div class="jumbotron jumbotron-fluid mb-3 pl-0 pt-0 pb-0 bg-white position-relative">
		<div class="h-100 tofront">
			<div class="row  justify-content-center ">
				<div class=" col-md-8  pr-0 pr-md-4 pt-4 pb-4 align-self-center">
					<p class="text-uppercase font-weight-bold">
                        <span class="catlist">
						
                          <a class="sscroll text-danger" href="/categories.html#robotics">robotics</a><span class="sep">, </span>
                        
                        </span>
					</p>
					<h2 class="display-4 mb-4 article-headline">Visual Servoing For Manipulators - Part I</h2>
					<div class="d-flex align-items-center">
						<!-- <small class="ml-3"> Akshay <span><a target="_blank" href="https://twitter.com/kumarakshay324" class="btn btn-outline-success btn-sm btn-round ml-1">Follow</a></span> -->
                            <span class="text-muted d-block mt-1">Jan 27, 2019 Â· <span class="reading-time">
  
  
    8 mins read
  
</span>
    </span>
						<!-- </small> -->
					</div>
				</div>
                
			</div>
		</div>
	</div>
</div>





<div class="container-lg pt-4 pb-4">
	<div class="row justify-content-center">
        
        
        <!-- Share -->
		<div class="col-lg-2 pr-4 mb-4 col-md-12">
			<div class="sticky-top sticky-top-offset text-center">
				<div class="text-muted">
					Share this
				</div>
				<div class="share d-inline-block">
					<!-- AddToAny BEGIN -->
					<div class="a2a_kit a2a_kit_size_32 a2a_default_style">
						<a class="a2a_dd" href="https://www.addtoany.com/share"></a>
						<a class="a2a_button_linkedin"></a>
						<a class="a2a_button_email"></a>
						<a class="a2a_button_reddit"></a>
						<a class="a2a_button_twitter"></a>
					</div>
					<script async src="https://static.addtoany.com/menu/page.js"></script>
					<!-- AddToAny END -->
				</div>
			</div>
		</div>
        
        
		<div class="col-md-12 col-lg-8 " style="text-align: justify;">
            
            <!-- Article -->
			<article class="article-post">                
			<p>Visual Servoing is one of the most used robotics in the industry for automation. It involves using computer-vision based realtime feedback of the task space for online control of manipulator end-effector pose while performing tasks. Servoing refers to using a closed-loop feedback mechanism to manipulate reference input signal to a system while eventually driving the system to the desired target. Extracted features from visual information relate the robot current configuration to the task at hand and the system generates high-level pose control commands towards task completion.</p>

<p><img src="/assets/images/visual_servoing/visual_servoing.gif" alt="Visual Servoing" /> <em>Visual Servoing</em></p>

<h3 id="introduction">Introduction</h3>

<p>Image processing represents the physical state of the object in the world such that it can be related to the robot pose. The fundamental geometric relationship between an object in 3D space and its projection in an image helps connect the visual feed to the world and the robot. Visual servoing is dependent on robot pose estimation, robot control and realtime image processing. The kinematics and dynamics of robots vary depending on the model thereby changing the control instructions.</p>

<p>Image processing is used for extraction of several features like points, edges and gradients in images. Such features help in segmentation, object detection and recognition. Such image features are macro level properties that are obtained after batch operations on individual image pixels. The higher the pixel resolution of the image, the better are algorithms at processing the image and obtaining accurate features at the expense of increased computational expense.</p>

<p><img src="/assets/images/visual_servoing/ip.jpg" alt="Object Detection, Object Recognition and Segmentation" /> <em>Object Detection, Object Recognition and Segmentation</em></p>

<p><strong>Visual servoing is a realtime operation and thus involves interpretation of features in one still image or multiple consecutive images or streo images or image flows.</strong></p>

<p><strong>Visual servoing for robot manipulators has two main paradigms based on camera mounting positions; eye-in-hand and eye-to-hand</strong>. Eye-in-hand paradigm has the camera mounted on the end-effector of the robot and moves around with it and thus, everything that the robot sees in the world is with reference to the end-effector cartesian pose. The eye-to-hand paradigm has the camera fixed in the world and all observations from the camera are transformed to robot frame.</p>

<p><img src="/assets/images/visual_servoing/paradigm.png" alt="Eye-in-hand and Eye-to-hand paradigms" /> <br /> <em>Eye-in-hand and Eye-to-hand paradigms</em></p>

<p><strong>Another feedback-interpretation based category of visual servoing has two direct and indirect servoing types that generate cartesian poses for the robot and joint angles for online motion respectively</strong>. The direct method is easy to use but slow while the latter is complex and fast.</p>

<h3 id="visual-servoing-schemes">Visual Servoing Schemes</h3>

<p>There are two most important visual servoing schemes - <strong>position-based visual servoing(PBVS) and image-based visual servoing(IBVS)</strong>. PBVS uses the visual features to reconstruct the 3D pose of objects of interest and compare it with the current pose to generate a cartesian error that the robot needs to operate on and converge onto the goal. IBVS scheme uses the 2D image of the world, obtains values of the relevant features on them and then manipulates the robot around until the values for the features converge to the desired ones.</p>

<p><img src="/assets/images/visual_servoing/schemes.jpg" alt="PBVS and IBVS" /> <br /> <em>PBVS and IBVS</em></p>

<h4 id="position-based-visual-servoing">POSITION-BASED VISUAL SERVOING</h4>

<p>The two main components of PBVS high-level operation are computer vision and robot kinematics. Computer vision is responsible for intepretation of the scene, extraction of features and representation of the same in 3D space. Thereafter, the attempt to diminish the cartesian error is translated into robot control instructions.</p>

<p>3D scene reconstruction from visual information makes it important to have accurate camera calibration and pose information such that knowledge about the world is correct and directs the robot to the right location in space. It is important to have accurate geometric transformations between the camera and the world and the camera and the robot end-effector.</p>

<p><img src="/assets/images/visual_servoing/pbvs.png" alt="Position Based Visual Servoing" /> <em>Position Based Visual Servoing</em></p>

<p>In the PBVS architecture, feature extraction from images is an easy step but 3D pose estimation from the visual feed is sophisticated and is very susceptible to many factors. This desired pose is generally derived based on the pose of the object to be operated on, by the robot. For instance, a pick-and-place task with static start and end poses defines the robot end-effector pose for the grasp/pick action as the desired pose and visually servos the robot to the same.</p>

<p>The reference control signal for the robot is the desired pose ( pdesired = (xdes, ydes, zdes, Î±des, Î²des, Î³des)), comprising of the position and the orientation of the end effector. Almost always, the robot current pose is obtained solely via the kinematics model and the vision system obtains the object pose as an independent exercise thereby making the calibration phase very critical.</p>

<h4 id="image-based-visual-servoing">IMAGE-BASED VISUAL SERVOING</h4>

<p>IBVS paradigm of visual servoing generates errors between desired and actual state/values of features in 2D images. Thereafter, the error is translated into robot relevant control commands and the robot is maneuvered until those values converge.</p>

<p>Given that IBVS does error computation and online feedback within the image plane itself, it is immune to the calibration parameters and inaccuracies. Contender image features that are to be converged to, could be as simple as positioning of the object of interest in the center of the image canvas or aligning the edges in image to the one from a standard image.</p>

<p><img src="/assets/images/visual_servoing/ibvs.png" alt="Image Based Visual Servoing" /> <em>Image Based Visual Servoing</em></p>

<p>Steps involves in IBVS have several sophistications and challenges. The repercussions involve delayed processing, computational limitations and image resolution.</p>

<ul>
  <li>Frame rates, noisy information, ambient-lighting inconsistencies and latency are the most challenging aspects of image acquisition and online processing step.</li>
  <li>Real-time image processing and feature extraction is a very computationally expensive process. Implementation of machine learning and deep learning steps enhance the efficiency of these operations at the expense of additional processing time overheads. Extraction of simple image features like edges and gradients is easy and existing tools are efficient at them. Unfortunately, most of the sought after features are object detection, identificatio and recognition which is slow at runtime even using pre-trained models.</li>
  <li>The comparison between desired feature values and current image features derives the error in the image plane.</li>
  <li>Final transformation of image plane error to robot level generates the reference signals for the robot. These reference signals are mostly kinematic but the challenge lies in obeying</li>
  <li>The generated reference signals are used by the robot to implement the control techniques.</li>
</ul>

<h3 id="image-processing-aspects-of-visual-servoing">Image Processing Aspects of Visual Servoing</h3>

<p>The most basic concepts of image processing and computer vision in visual servoing are camera calibration, color manipulation, feature definition and extraction.</p>

<h4 id="camera-model--calibration">CAMERA MODEL &amp; CALIBRATION</h4>

<p>An image is a 2D array of pixels, the smallest unit of predefined dimensions representing a particular color. Every camera has a 2D array of sensing elements that capture the light falling on it. In a digital camera, the frame grabber writes the digital data to an image plane with each pixel having a gray value of 0-255 representing the intensity of light on the sensing element.</p>

<p>Geometric relationship between the contents of an image and the real world is the most fundamental concept of visual servoing. It is important to understand the camera coordinate frame thus understanding the relationship between its trasnformation to other frames.</p>

<p><img src="/assets/images/visual_servoing/camera_coordinates.png" alt="Camera Coordinate System" /> <em>Camera Coordinate System</em></p>

<p>The camera plane carrying the 2D sensing array is called the image plane and is situated at a distance Î» ahead of the center of projection. The optical axis is the central axis along the Z direction that contains the center of projection and the principal point (point of intersection of the optical axis and the image plane).</p>

<p>The concept of perspective projection defines the relationship between the actual object coordinates and its representation in the image plane. Using the pinhole camera approximation, the lens is assumed to be an ideal pinhole located at the focal point of the lens. It casts the light falling onto it, onto the image plane. The world coordinates of a point P(x, y, z), its image plane equivalent and the camera origin are believed to be collinear and give the following relationship between the coordinates.</p>

<p>Reference coordinate frames are important to visual servoing which includes a world frame, a robot base frame, an end-effector frame and a camera frame. Accurate transformations between these frames determine correct target pose for the robot.</p>

<h4 id="image-features-of-interest">IMAGE FEATURES OF INTEREST</h4>

<p>There are several micro and macro features in images that become regions of interest for the algorithms. Usually, any region of an image that may have a mathematical representation of pixel manipulation can be a feature. Features could be either hand-crafted and visibly understandable or merely a mathematical representation generated by the computer vision algorithms based on annotated information from training data.</p>

<p>Hand-crafted featurs are very evident and intuitively understandable like edges, blobs and corners among others while other non-standard features are usually learned by CNNs or other ML techniques over the training period.</p>

<p><img src="/assets/images/visual_servoing/cnn_visualize.png" alt="CNN generated features" /> <em>CNN generated features</em></p>

<p><img src="/assets/images/visual_servoing/edge.jpeg" alt="Edges In An Image" /> <em>Edges In An Image</em></p>
<hr />

<p>This part I of the article is an intuitive walk-through of the high-level concepts of visual servoing. Part II of this topic explains interaction matrices, image jacobians and robot kinematics. It also explains a demo implementation of visual servoing.</p>

                
			</article>
			
			<!-- Tags -->
			<div class="mb-4">
				<span class="taglist">
				
				  <a class="sscroll btn btn-light btn-sm font-weight-bold" href="/tags.html#blog_post">blog_post</a>
				
				</span>
			</div>
 
            <!-- Mailchimp Subscribe Form -->
            <!-- 
			<div class="border p-5 bg-lightblue">
				<div class="row justify-content-between">
					<div class="col-md-6 mb-2 mb-md-0">
						<h5 class="font-weight-bold">Join Newsletter</h5>
						 Get the latest news right in your inbox. We never spam!
					</div>
					<div class="col-md-6">
						<div class="row">
                            <form action="https://wowthemes.us11.list-manage.com/subscribe/post?u=8aeb20a530e124561927d3bd8&amp;id=8c3d2d214b" method="post" name="mc-embedded-subscribe-form" class="wj-contact-form validate w-100" target="_blank" novalidate>
                            <div class="mc-field-group">
							
								<input type="email" placeholder="Enter e-mail address" name="EMAIL" class="required email form-control w-100" id="mce-EMAIL" autocomplete="on" required>
							
							
								<button type="submit" value="Subscribe" name="subscribe" class="heart btn btn-success btn-block w-100 mt-2">Subscribe</button>
							
                            </div>
                            </form>
						</div>
					</div>
				</div>
			</div>
             -->
            
            
             <!-- Author Box -->
                <!-- 				
				<div class="row mt-5">
					<div class="col-md-2 align-self-center">
                         
                        <img class="rounded-circle" src="/assets/images/AKSHAY_KUMAR.jpg" alt="Akshay" width="90"/>
                         
					</div>
					<div class="col-md-10">		
                        <h5 class="font-weight-bold">Written by Akshay <span><a target="_blank" href="https://twitter.com/kumarakshay324" class="btn btn-outline-success btn-sm btn-round ml-2">Follow</a></span></h5>
						I am a Computer Vision Engineer at Invisible AI in San Francisco working on applied computer vision, edge-computing and baffling decision-making algorithms for industrial applications.					
					</div>
				</div>				
                 -->
            
            <!-- Comments -->
            
                <!--  Don't edit anything here. Set your disqus id in _config.yml -->

<div id="comments" class="mt-5">
    <div id="disqus_thread">
    </div>
    <script type="text/javascript">
        var disqus_shortname = 'kumarakshay-me'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>
    Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
    </noscript>
</div>
            
            
		</div>
        
        
	</div>
</div>


<!-- Aletbar Prev/Next -->
<div class="alertbar">
    <div class="container">
        <div class="row prevnextlinks small font-weight-bold">
          
            <div class="col-md-6 rightborder pl-0">
                <a class="text-dark" href="/rt-linux/"> Real Time Operating Systems In Robotics</a>
            </div>
          
          
            <div class="col-md-6 text-right pr-0">
                <a class="text-dark" href="/model-predictive-control-part1/"> Model Predictive Control In Robotics - Part I </a>
            </div>
          
        </div>
    </div>
</div>

    </main>


    <!-- Scripts: popper, bootstrap, theme, lunr -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

    <script src="/assets/js/theme.js"></script>


    <!-- Footer -->
    <!-- <footer class="bg-white border-top p-3 text-muted small">
        <div class="container">
        <div class="row align-items-center justify-content-between">
            <div>
                <span class="navbar-brand mr-2 mb-0"><strong>Mundana</strong></span>
                <span>Copyright Â© <script>document.write(new Date().getFullYear())</script>.</span>

                <a class="text-dark ml-1" target="_blank" href="https://github.com/wowthemesnet/mundana-theme-jekyll"><i class="fab fa-github"></i> Fork on Github</a>

            </div>
            <div>
                Made with <a target="_blank" class="text-dark font-weight-bold" href="https://www.wowthemes.net/mundana-jekyll-theme/"> Mundana Jekyll Theme </a> by <a class="text-dark" target="_blank" href="https://www.wowthemes.net">WowThemes</a>.
            </div>
        </div>
        </div>
    </footer> -->

    <!-- All this area goes before </body> closing tag --> 


</body>

</html>
