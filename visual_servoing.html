    <!DOCTYPE HTML>

<head>
<style>

div.blog_box {
  margin-left: 30%;
  margin-right: 10%;

  background-color: #f5f5ef;
  /*border: 1px black;*/
  opacity: 1.0;
  filter: alpha(opacity=100); /* For IE8 and earlier */
}

div.blog_box_sidenav {
  margin-left: 8%;
  margin-right: 10%;
  position: fixed;
  background-color: #f5f5ef;
  border: 1px solid #dbdbd5;
  height: auto;
  width: 350px;
  opacity: 1.0;
  filter: alpha(opacity=100); /* For IE8 and earlier */
}


div.column{
  /*float: right;*/
  margin-right: 0%;
  margin-left: 0%;  
  width: 30%;
  /*width*/: 30%;
  position: fixed;
}

.blog_box_sidenav p:hover{
  color: #140440;
  font-weight: 500;
  /*text-decoration: bold;*/
  /*background-color: #cfc ;*/

}

</style>
</head>

<html>
    <head>
        <title>Visual Servoing for Manipulators - AKSHAY KUMAR</title>
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <meta name="description" content="" />
        <meta name="keywords" content="" />
        <!--[if lte IE 8]><script src="css/ie/html5shiv.js"></script><![endif]-->
        <script src="js/jquery.min.js"></script>
        <script src="js/jquery.dropotron.min.js"></script>
        <script src="js/skel.min.js"></script>
        <script src="js/skel-layers.min.js"></script>
        <script src="js/init.js"></script>
        <noscript>
            <link rel="stylesheet" href="css/skel.css" />
            <link rel="stylesheet" href="css/style.css" />
        </noscript>
        <!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
    </head>
    <body class="homepage">

        <!-- Header Wrapper -->
            <div class="wrapper style1">
            
            <!-- Header -->

                        
                        <!-- Nav -->
                            <div class="navbox">
                                <ul style="white-space:nowrap;"><br>
                                    <li class="active" style="display:inline; "><a href="portfolio.html" style="text-decoration: none; font-size: 25px; font-weight: 500; color: white">PORTFOLIO &emsp; </a> </li>                                 
                                    <li class="active" style="display:inline; "><a href="images/AKSHAY_KUMAR_RESUME_1PAGE.pdf" target="_blank" style="text-decoration: none; font-size: 25px; font-weight: 500; color: white ">RESUME &emsp;</a></li>

                                    <li class="active" style="display:inline; text-decoration: none;"><a href="index.html" style="text-decoration: none;font-size: 25px; font-weight: 500; color: white">HOME &emsp;</a></li>

                                </ul>
                            </div>
                </div>
                
            </div>          

            <!-- Introduction -->
            <div class="wrapper style6" align="justify" >

            <br>

            <!-- <div class="column"> -->
                <div class="blog_box_sidenav" align="left" >
                    <center>
                    <br>
                    <span style="font-size:25px;text-decoration: none;">LATEST POSTS</span>
                    </center><br>

                    <a style="display:block;font-size:16px;color:black;;text-decoration:none;margin-left:2%;margin-right:10%margin-top:5%" 
                    href="advanced_conntrol.html">
                        <p style="margin-right:2%; margin-left: 2%"> Control Techniques for Robot Manipulators</p>
                    </a>

                    <a style="display:block;font-size:16px;color:black;;text-decoration:none;margin-left:2%;margin-right:10%margin-top:5%" 
                    href="ros.html">
                        <p style="margin-right:2%; margin-left: 2%"> Robot Operating System (ROS) - Command Line Tools</p>
                    </a>

                    <a style="display:block;font-size:16px;color:black;;text-decoration:none;margin-left:2%;margin-right:10%margin-top:5%" 
                    href="sampling.html">
                        <p style="margin-right:2%; margin-left: 2%">  Sampling-based Motion Planners</p>
                    </a>

                    <a style="display:block;font-size:16px;color:black;;text-decoration:none;margin-left:2%;margin-right:10%margin-top:5%" 
                    href="mp_intro.html">
                        <p style="margin-right:2%; margin-left: 2%">  Motion Planning in Robotics</p>
                    </a>

                    <a style="display:block;font-size:16px;color:black;;text-decoration:none;margin-left:2%;margin-right:10%margin-top:5%" 
                    href="visual_slam.html">
                        <p style="margin-right:2%; margin-left: 2%">  Visual SLAM - An Introduction</p>
                    </a>

                    <a style="display:block;font-size:16px;color:black;;text-decoration:none;margin-left:2%;margin-right:10%margin-top:5%" 
                    href="coverage.html">
                        <p style="margin-right:2%; margin-left: 2%">  Coverage Problem in Mobile Robotics</p>
                        <br>
                    </a>
                    <br>
                </div>

            <div id="mySidenav" class="sidenav">
<!--              <a href="#" id="about">About
 -->

                     <a href="mailto:singhakshay324@gmail.com" target="_blank" id="gmail1"><img src="images/contacts/gmail.png" style="width:50px;height:50px;"> </a>

                     <a href="mailto:akumar5@wpi.edu" target="_blank" id="gmail2"><img src="images/contacts/outlook.png" style="width:50px;height:50px;"></a>

                    <a href="http://in.linkedin.com/in/kumarakshay324" target="_blank" id="linkedin"><img src="images/contacts/linkedin.png" style="width:50px;height:50px;;"></a></center>

                     <a href="https://github.com/kumar-akshay324" target="_blank" id="github"><img src="images/contacts/github.png" style="width:50px;height:50px;"></a>

                    <a href=" http://www.quora.com/profile/Akshay-Singh-66" target="_blank" id="quora"><img src="images/contacts/quora.png" style="width:50px;height:50px;;"></a>

                    <a href="http://www.facebook.com/singhakshay324" target="_blank" id="social"><img src="images/contacts/fb.png" style="width:50px;height:50px;;"></a>


<!--              <a href="#" id="blog">Blog</a>
              <a href="#" id="projects">Projects</a>
              <a href="#" id="contact">Contact</a>
 -->            </div>

            <div class="blog_box" align="justify" >
                    <!-- <center><img src="images/posts.jpg" style="width:1120px;height:706px;margin-left:5%;"></center> -->
                <br>
                    <h2 style="font-size:40px;font-weight: 500">VISUAL SERVOING FOR MANIPULATORS</h2>
                <br>

                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;">

                Visual Servoing is one of the most sought after robotics features used in the industry for automated tasks. As the name suggests, it involves using computer-vision for online control of manipulator end-effector pose while performing tasks. Servoing refers to using a feedback mechanism to manipulate reference input signal to a system. Extracted features from visual information are used to drive the robot pose to desired location.
                </p>

                <center>
                    <figure>
                        <img src="images/blogs/visual_servoing/visual_servoing.gif" style="width:500;height:370px;">
                        <figcaption>Visual Servoing - Source (Google)</figcaption>
                        <br>
                    </figure>
                </center>

                <h1 style="text-align:left;margin-left:200px;font-size:20px; ">Introduction</h1>
                <br>

                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;">

                Visual servoing is dependent on robot pose estimation, robot control and realtime image processing. The kinematics and dynamics of robots vary depending on the model but the concepts of image processing largely remain constant. Image processing represents the physical state of the object in the world such that it can be related to the robot pose.
                <br><br>
                Image processing is used for extraction of several features like points, edges and gradients in images. Such features help in segmentation, object detection and recognition. Such image features are macro level properties that are obtained after batch operations on individual image pixels. The higher the pixel resolution of the image, the better are algorithms at processing the image and obtaining accurate features at the expense of increased computational expense. <b style="font-weight: 500">Visual servoing is a realtime operation and thus involves interpretation of features in one still image, multiple consecutive images, streo images or image flows.</b>               
                <br><br>
                Visual servoing for robot manipulators has two main paradigms based on camera positioning; <b style="font-weight: 500">eye-in-hand and eye-to-hand</b>. Eye-in-hand paradigm has the camera mounted on the end-effector of the robot and moves around with it and thus, everything that the robot sees in the world is with reference to the end-effector cartesian pose. The eye-to-hand paradigm has the camera fixed in the world and all observations from the camera are transformed to robot frame.
                </p>

                <center>
                    <figure>
                        <img src="images/blogs/visual_servoing/paradigm.png" style="width:561;height:214px;">
                        <figcaption>Eye-in-hand and Eye-to-hand paradigms</figcaption>
                    </figure>
                    <br>
                </center>

                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;">
                    Another feedback-interpretation based category of visual servoing has two <b style="font-weight: 500">direct and indirect servoing types that generate cartesian poses for the robot and joint angles for online motion respectively.</b> The direct method is easy to use but slow while the latter is complex and fast.
                </p>
                <br>
                <h1 style="text-align:left;margin-left:200px;font-size:20px ">Visual Servoing Schemes</h1>
                <br>
                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;">
                    There are two most important visual servoing schemes - <b style="font-weight: 500"> position-based visual servoing(PBVS) and image-based visual servoing(IBVS). </b> PBVS uses the visual features to reconstruct the 3D pose of objects of interest and compare it with the current pose to generate a cartesian error that the robot needs to operate on and converge onto the goal. IBVS scheme uses the 2D image of the world, obtains values of the relevant features on them and then manipulates the robot around until the values converge to the desired ones.
                </p> 

                <center>
                    <figure>
                        <img src="images/blogs/visual_servoing/schemes.jpg" style="width:353px;height:295px;">
                        <figcaption>PBVS and IBVS </figcaption>
                    </figure>
                    <br>
                </center>

                <center>
                <p style="text-align:center;font-size:20px; "> <b style="font-weight: 500">POSITION-BASED VISUAL SERVOING</b> </p>
                </center>

                <p style="column-width:1000px;margin-left:250px;margin-right:200px; text-align:justify;">

                The two main components of PBVS high-level operation are computer vision and robot kinematics. Computer vision is responsible for intepretation of the scene, extract features and represent the same in 3D space. Thereafter, the attempt to diminish the cartesian error is translated into robot control instructions.
                <br><br>
                3D scene reconstruction from visual information makes it important to have accurate camera calibration and pose information such that information about the world is correct and directs the robot to the right location in space. It is important to have accurate transformation between the camera and the world and the camera and the robot end-effector.  
                <center>
                    <figure>
                        <img src="images/blogs/visual_servoing/pbvs.png" style="width:640px;height:130px;">
                        <figcaption>PBVS</figcaption>
                    </figure>
                </center>
                </p>

                <p style="column-width:1000px;margin-left:250px;margin-right:200px; text-align:justify;">
                    In the PBVS architecture, feature extraction from images is an easy step but 3D pose estimation from the visual feed is sophisticated and is very susceptible to many factors. This desired pose is generally derived based on the pose of the object to be operated on, by the robot. For instance, a pick-and-place task with static start and end poses defines the approach pose of the robot end-effector
                    <br><br>
                    The reference control signal for the robot is the desired pose (<b style="font-weight: 500"><i> p<sub>desired</sub> = (x<sub>des</sub>, y<sub>des</sub>, z<sub>des</sub>, &#945;<sub>des</sub>, &#946;<sub>des</sub>, &#947;<sub>des</sub>)</i></b>), comprising of the position and the orientation.
                </p>

                <center>
                <p style="text-align:center;font-size:20px; "> <b style="font-weight: 500">IMAGE-BASED VISUAL SERVOING</b> </p>
                </center>

                <p style="column-width:1000px;margin-left:250px;margin-right:200px; text-align:justify;">

                IBVS paradigm of visual servoing generates errors between desired and actual state/values of features in 2D images. Thereafter, the error is translated into robot relevant control commands.
                <br><br>
                Given that IBVS does error computation and online feedback within the image plane, it is immune to the calibration parameters and inaccuracies. Contender image features that are to be converged to, could be as simple as positioning of the object of interest in the center of the image canvas or presence of edges in image.

                <center>
                    <figure>
                        <img src="images/blogs/visual_servoing/ibvs.png" style="width:640px;height:130px;">
                        <figcaption>IBVS</figcaption>
                    </figure>
                </center>
                </p>

                <p style="column-width:1000px;margin-left:250px;margin-right:200px; text-align:justify;">
                    Steps involves in IBVS have several sophistications and challenges. The repercussions involve delayed processing, computational limitations and image resolution. 

                    <ul style="column-width:1000px;margin-left:270px;margin-right:200px;text-align:justify;list-style-type: disc">
                        <li>
                            Frame rates, noisy information, ambient-lighting inconsistencies and latency are the most challenging aspects of image acquisition and online processing step. Feature extraction
                        </li>
                        <li>
                            Real-time image processing and feature extraction is a very computationally expensive process. Implementation of machine learning and deep learning steps enhance the efficiency of these operations at the expense of additional processing time overheads.
                        </li>
                        <li>
                            The comparison between desired feature values and current image features derives the error in the image plane. 
                        </li>
                        <li>
                            Final transformation of image plane error to robot level generates the reference signals for the robot.
                        </li>
                        <li>
                            The generated reference signals are used by the robot to implement the <a href="advanced_conntrol.html">control techniques.</a>
                        </li>
                    </ul>
  
                </p>

                <h1 style="text-align:left;margin-left:200px;font-size:20px ">Image Processing Aspects of Visual Servoing</h1>
                <br>
                <p style="column-width:1000px;margin-left:200px;margin-right:200px;text-align:justify;">
                    The most basic concepts of image processing and computer vision in visual servoing are camera calibration, .
                </p> 

            </div>
            </div>

            <p style="column-width:1000px;margin-left:550px;margin-right:200px;text-align:center;font-size: 22px;font-weight: 500;color: red">
                <i>
                IF YOU LIKED THE ARTICLE, DON'T FORGET TO LEAVE A REACTION OR A COMMENT!                         
                </i>
            </p>

            <div id="disqus_thread" style="column-width: 1000px;margin-left: 570px;margin-right: 200px;"></div>
            <script>

            /**
            *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
            *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

            var disqus_config = function () {
            this.page.url = "http://kumarakshay.me/visual_servoing.html";  // Replace PAGE_URL with your page's canonical URL variable
            this.page.identifier = 170; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
            };

            (function() { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');
            s.src = 'https://kumarakshay-me.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
            })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    
        <!-- Section One -->
            <div class="wrapper style2">

                <p style="margin-bottom:0;padding-bottom:0;"><hr width="50%"><center>Copyright @Akshay Kumar | Last Updated on 05/25/2019</center></p> 

            </div>
<div align=center><a href='https://www.counter12.com'><img src='https://www.counter12.com/img-y9Z8xYWb7W273YW2-50.gif' border='0' alt='counter'></a><script type='text/javascript' src='https://www.counter12.com/ad.js?id=y9Z8xYWb7W273YW2'></script></div>


    </body>
</html>
